{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web_Scrapping_Dataset_AGUA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNufPreZMCNRqKV/Wowdjpv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvScEBRMr_zb"
      },
      "source": [
        "### Obtención de datos meteorológicos API de AEMET."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGmbKaCNsMzU"
      },
      "source": [
        "Obtenemos las diferentes estaciones con sus cordenadas y las precipitaciones en (l /m3) registradas en la hora previa a una fehca dada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3LE-VSfey40"
      },
      "source": [
        "import requests\n",
        "import urllib\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://opendata.aemet.es/opendata/api/observacion/convencional/todas\"\n",
        "\n",
        "querystring = {\"api_key\":\"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJtb2VsbW9hQHVvYy5lZHUiLCJqdGkiOiI4ZDdhMWVmYS05NTcxLTQ0Y2MtYThhNi1iZjRkMmUyYWE0ZWEiLCJpc3MiOiJBRU1FVCIsImlhdCI6MTYzNTU5MTc4MiwidXNlcklkIjoiOGQ3YTFlZmEtOTU3MS00NGNjLWE4YTYtYmY0ZDJlMmFhNGVhIiwicm9sZSI6IiJ9.Gc4Qmws53ifnrjBdqLAjKRsNLW26SI_7OFg0OzC2Tdg\"}\n",
        "\n",
        "headers = {\n",
        "    'cache-control': \"no-cache\"\n",
        "    }\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
        "\n",
        "url=''.join(response.text).split(',')[2].split('\" :')[1][2:-1]\n",
        "file = urllib. request. urlopen(url)\n",
        "lon,lat,name,prec,time=[],[],[],[],[]\n",
        "temp1,temp2,temp3,temp4,temp5=None,None,None,None,None\n",
        "cnt=0\n",
        "for i,line in enumerate(file):\n",
        "  decoded_line = line.decode('latin1')\n",
        "  \n",
        "  if len(line)>10:\n",
        "    if str((str(line).split(':')[0])).split('\"')[1] == 'lon':\n",
        "      temp1=str(str((str(line).split(':')[1])).split(' ')[1]).split(',')[0]\n",
        "     \n",
        "    elif str((str(line).split(':')[0])).split('\"')[1] == 'lat':\n",
        "      temp2=str(str((str(line).split(':')[1])).split(' ')[1]).split(',')[0]\n",
        "     \n",
        "    elif str((str(line).split(':')[0])).split('\"')[1] == 'prec':\n",
        "      temp3=str(str((str(line).split(':')[1])).split(' ')[1]).split(',')[0]\n",
        "\n",
        "    elif str((str(line).split(':')[0])).split('\"')[1] == 'fint':\n",
        "      temp4=str((str(line).split(':')[1])).split('\"')[1]\n",
        "    elif str((str(line).split(':')[0])).split('\"')[1]=='ubi':\n",
        "      temp5=str((str(line).split(':')[1])).split('\"')[1]\n",
        "\n",
        "    if temp1!=None and temp2!=None and temp3!=None and temp4!=None:\n",
        "        prec.append(temp3) \n",
        "        lon.append(temp1)\n",
        "        lat.append(temp2)\n",
        "        time.append(temp4)\n",
        "        name.append(temp5)\n",
        "        temp1,temp2,temp3,temp4,temp5=None,None,None,None,None\n",
        "      \n",
        "     "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "TvpoJmZsmRaE",
        "outputId": "ec18cb53-bf13-41ae-eaa8-2675a64fbec4"
      },
      "source": [
        "d = {'name':name,'lon': lon, 'lat': lat,'time':time,'prec':prec}\n",
        "df_aemet = pd.DataFrame(data=d)\n",
        "df_aemet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>lon</th>\n",
              "      <th>lat</th>\n",
              "      <th>time</th>\n",
              "      <th>prec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "      <td>0.963335</td>\n",
              "      <td>41.213894</td>\n",
              "      <td>2021-11-06T19</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ALFORJA</td>\n",
              "      <td>1.178894</td>\n",
              "      <td>41.14972</td>\n",
              "      <td>2021-11-06T19</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>REUS/AEROPUERTO</td>\n",
              "      <td>1.260838</td>\n",
              "      <td>41.293053</td>\n",
              "      <td>2021-11-06T19</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VALLS</td>\n",
              "      <td>1.249167</td>\n",
              "      <td>41.123894</td>\n",
              "      <td>2021-11-06T19</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TARRAGONA  FAC. GEOGRAFIA</td>\n",
              "      <td>1.519269</td>\n",
              "      <td>41.417053</td>\n",
              "      <td>2021-11-06T19</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18446</th>\n",
              "      <td>LAS PALMAS G.C. SAN CRIST\\xd3BAL</td>\n",
              "      <td>-15.421389</td>\n",
              "      <td>28.089722</td>\n",
              "      <td>2021-11-07T18</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18447</th>\n",
              "      <td>LAS PALMAS DE GC. PLAZA  DE LA FERIA</td>\n",
              "      <td>-15.595833</td>\n",
              "      <td>28.113056</td>\n",
              "      <td>2021-11-07T18</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18448</th>\n",
              "      <td>MASPALOMAS</td>\n",
              "      <td>-13.51021</td>\n",
              "      <td>27.735832</td>\n",
              "      <td>2021-11-07T18</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18449</th>\n",
              "      <td>TEGUISE LA GRACIOSA-HELIPUERTO</td>\n",
              "      <td>-18.115</td>\n",
              "      <td>29.229586</td>\n",
              "      <td>2021-11-07T18</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18450</th>\n",
              "      <td>DEHESA-REFUGIO</td>\n",
              "      <td>-17.88889</td>\n",
              "      <td>27.725279</td>\n",
              "      <td>2021-11-07T18</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18451 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       name         lon  ...           time prec\n",
              "0                                      None    0.963335  ...  2021-11-06T19  0.0\n",
              "1                                   ALFORJA    1.178894  ...  2021-11-06T19  0.0\n",
              "2                           REUS/AEROPUERTO    1.260838  ...  2021-11-06T19  0.0\n",
              "3                                     VALLS    1.249167  ...  2021-11-06T19  0.0\n",
              "4                 TARRAGONA  FAC. GEOGRAFIA    1.519269  ...  2021-11-06T19  0.0\n",
              "...                                     ...         ...  ...            ...  ...\n",
              "18446      LAS PALMAS G.C. SAN CRIST\\xd3BAL  -15.421389  ...  2021-11-07T18  0.0\n",
              "18447  LAS PALMAS DE GC. PLAZA  DE LA FERIA  -15.595833  ...  2021-11-07T18  0.0\n",
              "18448                            MASPALOMAS   -13.51021  ...  2021-11-07T18  0.0\n",
              "18449        TEGUISE LA GRACIOSA-HELIPUERTO     -18.115  ...  2021-11-07T18  0.0\n",
              "18450                        DEHESA-REFUGIO   -17.88889  ...  2021-11-07T18  0.0\n",
              "\n",
              "[18451 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf_MgntB126y"
      },
      "source": [
        "Obtener propietario de un sitio web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHYZQ1ym1hxZ",
        "outputId": "a22304e6-32e0-4c9a-b021-93d9d31ffba0"
      },
      "source": [
        "!pip3 install python-whois\n",
        "import whois\n",
        "print(whois.whois('https://www.embalses.net/'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-whois\n",
            "  Downloading python-whois-0.7.3.tar.gz (91 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▋                            | 10 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 20 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 30 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 91 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from python-whois) (0.16.0)\n",
            "Building wheels for collected packages: python-whois\n",
            "  Building wheel for python-whois (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-whois: filename=python_whois-0.7.3-py3-none-any.whl size=87721 sha256=418e37a38f2f5d572d027e70c459ad15252181efa0805fc83c208742e015a024\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/05/f7/895ce5a73665f77c8274a7d55e34fb3e6b4abbb9a7637e215b\n",
            "Successfully built python-whois\n",
            "Installing collected packages: python-whois\n",
            "Successfully installed python-whois-0.7.3\n",
            "{\n",
            "  \"domain_name\": [\n",
            "    \"EMBALSES.NET\",\n",
            "    \"embalses.net\"\n",
            "  ],\n",
            "  \"registrar\": \"ENOM, INC.\",\n",
            "  \"whois_server\": \"WHOIS.ENOM.COM\",\n",
            "  \"referral_url\": null,\n",
            "  \"updated_date\": \"2017-03-10 20:36:19\",\n",
            "  \"creation_date\": \"2005-12-05 17:45:51\",\n",
            "  \"expiration_date\": [\n",
            "    \"2022-12-05 17:45:51\",\n",
            "    \"2022-12-05 17:45:00\"\n",
            "  ],\n",
            "  \"name_servers\": [\n",
            "    \"DNS1.NAME-SERVICES.COM\",\n",
            "    \"DNS2.NAME-SERVICES.COM\",\n",
            "    \"DNS3.NAME-SERVICES.COM\",\n",
            "    \"DNS4.NAME-SERVICES.COM\",\n",
            "    \"DNS5.NAME-SERVICES.COM\"\n",
            "  ],\n",
            "  \"status\": [\n",
            "    \"clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited\",\n",
            "    \"clientTransferProhibited https://icann.org/epp#clientTransferProhibited\",\n",
            "    \"clientDeleteProhibited https://www.icann.org/epp#clientDeleteProhibited\",\n",
            "    \"clientTransferProhibited https://www.icann.org/epp#clientTransferProhibited\"\n",
            "  ],\n",
            "  \"emails\": [\n",
            "    \"ttwpslcrw@whoisprivacyprotect.com\",\n",
            "    \"ABUSE@ENOM.COM\"\n",
            "  ],\n",
            "  \"dnssec\": \"unsigned\",\n",
            "  \"name\": \"Whois Agent (643287951)\",\n",
            "  \"org\": \"Whois Privacy Protection Service, Inc.\",\n",
            "  \"address\": [\n",
            "    \"PO Box 639\",\n",
            "    \"C/O embalses.net\"\n",
            "  ],\n",
            "  \"city\": \"Kirkland\",\n",
            "  \"state\": \"WA\",\n",
            "  \"zipcode\": \"98083\",\n",
            "  \"country\": \"US\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4KxateGIOiE"
      },
      "source": [
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from urllib.request import Request\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "def get_page(url):\n",
        "    \"\"\"Scrapes a URL and returns the HTML source.\n",
        "    \n",
        "    Args:\n",
        "        url (string): Fully qualified URL of a page.\n",
        "    \n",
        "    Returns:\n",
        "        soup (string): HTML source of scraped page.\n",
        "    \"\"\"\n",
        "\n",
        "    response = urlopen(Request(url, headers={'User-Agent': 'Mozilla'}))\n",
        "    soup = BeautifulSoup(response, \n",
        "                         'html.parser', \n",
        "                         from_encoding=response.info().get_param('charset'))\n",
        "    \n",
        "    return soup"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMjQNMzHIYa0",
        "outputId": "0a0fc8c5-9ffd-4041-a712-11c0af4b7340"
      },
      "source": [
        "robots = get_page(\"https://www.embalses.net/robots.txt\")\n",
        "robots\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "User-Agent: *\n",
              "Disallow: /contenidos/"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbCf857heGrN"
      },
      "source": [
        "!curl -X GET --header 'Accept: text/plain' 'https://opendata.aemet.es/opendata/api/prediccion/especifica/municipio/horaria/252'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLJdvZENLACk"
      },
      "source": [
        "def get_sitemaps(robots):\n",
        "    \"\"\"Parse a robots.txt file and return a Python list containing any sitemap URLs found.\n",
        "\n",
        "    Args:\n",
        "        robots (string): Contents of robots.txt file.\n",
        "    \n",
        "    Returns:\n",
        "        data (list): List containing each sitemap found.\n",
        "    \"\"\"\n",
        "\n",
        "    data = []\n",
        "    lines = str(robots).splitlines()\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith('Sitemap:'):\n",
        "            split = line.split(':', maxsplit=1)\n",
        "            data.append(split[1].strip())\n",
        "\n",
        "    return data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-zZzV7IJJ90",
        "outputId": "adef1a35-df15-420c-e1b0-8569fae72930"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "xmlDict = {}\n",
        "\n",
        "r = requests.get(\"https://www.embalses.net/\")\n",
        "xml = r.text\n",
        "\n",
        "soup = BeautifulSoup(xml)\n",
        "sitemapTags = soup.find_all(\"sitemap\")\n",
        "\n",
        "print(\"The number of sitemaps are {0}\".format(len(sitemapTags)))\n",
        "\n",
        "for sitemap in sitemapTags:\n",
        "    xmlDict[sitemap.findNext(\"loc\").text] = sitemap.findNext(\"lastmod\").text\n",
        "\n",
        "print(xmlDict)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of sitemaps are 0\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBTyqwhXUBjc"
      },
      "source": [
        "Obtención de datos de embalses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00473Nv552jS",
        "outputId": "4501644a-ea64-4d22-d569-cf9bb511b904"
      },
      "source": [
        "!pip3 install requests\n",
        "import requests"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGcOLdU855-Y"
      },
      "source": [
        "page = requests.get('https://www.embalses.net/')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asvtyGHd6co4"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(page.content)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNRkzxPa7oZS",
        "outputId": "8dc86b12-f762-48ac-9578-51ee9d055ccd"
      },
      "source": [
        "print(soup.title.string)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embalses.net - Estado de los Embalses, pantanos y presas de España\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yYULwocdlKU"
      },
      "source": [
        "Obtención de las url de las comunidades."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SsFgkkG7xjd",
        "outputId": "10675aaf-a02b-4bc4-ed88-3a35dfa1c179"
      },
      "source": [
        "url_comunidades=[]\n",
        "for i in soup.find_all('a'):\n",
        "  try:\n",
        "    if len(str(i).split('href=\"')[1].split('\"')[0].split(\"/\"))>3:\n",
        "    #print(str(i).split('href=\"')[1].split('\"')[0].split(\"/\"))\n",
        "      if str(i).split('href=\"')[1].split('\"')[0].split(\"/\")[3].startswith('comunidad-'):  \n",
        "        print(str(i).split('href=\"')[1].split('\"')[0])\n",
        "        url_comunidades.append(str(i).split('href=\"')[1].split('\"')[0])\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.embalses.net/comunidad-1-andalucia.html\n",
            "https://www.embalses.net/comunidad-2-aragon.html\n",
            "https://www.embalses.net/comunidad-3-asturias.html\n",
            "https://www.embalses.net/comunidad-6-canarias.html\n",
            "https://www.embalses.net/comunidad-7-cantabria.html\n",
            "https://www.embalses.net/comunidad-9-castilla-y-leon.html\n",
            "https://www.embalses.net/comunidad-8-castilla-la-mancha.html\n",
            "https://www.embalses.net/comunidad-10-cataluna.html\n",
            "https://www.embalses.net/comunidad-13-comunidad-de-madrid.html\n",
            "https://www.embalses.net/comunidad-17-comunidad-valenciana.html\n",
            "https://www.embalses.net/comunidad-11-extremadura.html\n",
            "https://www.embalses.net/comunidad-12-galicia.html\n",
            "https://www.embalses.net/comunidad-4-islas-baleares.html\n",
            "https://www.embalses.net/comunidad-16-la-rioja.html\n",
            "https://www.embalses.net/comunidad-15-navarra.html\n",
            "https://www.embalses.net/comunidad-5-pais-vasco.html\n",
            "https://www.embalses.net/comunidad-14-region-de-murcia.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVPJ46gadnzr"
      },
      "source": [
        "Obtención de las url de cada embalse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orPMh_xYazil"
      },
      "source": [
        "url_pantano=[]\n",
        "for i in url_comunidades:\n",
        "  sub_page = requests.get(i)\n",
        "  sub_soup = BeautifulSoup(sub_page.content)\n",
        "  for j in sub_soup.find_all('a'):\n",
        "    if len(str(j).split('href=\"')[1].split('\"')[0].split(\"/\"))>3:\n",
        "      if str(j).split('href=\"')[1].split('\"')[0].split(\"/\")[3].startswith('pantano-'): \n",
        "        #print(str(j).split('href=\"')[1].split('\"')[0])\n",
        "        url_pantano.append(str(j).split('href=\"')[1].split('\"')[0])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZNoho_DdrfU"
      },
      "source": [
        "Obtención de los datos de cada embalse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjPwreXUdamq"
      },
      "source": [
        "values_dict={'Fecha':[],'hm':[],'Diff':[]}\n",
        "result={}\n",
        "for i in url_pantano:\n",
        "  sub_sub_page = requests.get(i)\n",
        "  sub_sub_soup = BeautifulSoup(sub_sub_page.content)\n",
        "  pantano=i.split('.')[-2].split('-')[-1]\n",
        "  result[pantano]={'Fecha':[],'hm':[],'Diff':[]}\n",
        "  for j in list(sub_sub_soup.find('tbody'))[1:]:\n",
        "    if len(str(j).split('>'))==13: \n",
        "      result[pantano]['Fecha'].append(str(j).split('>')[3].split('<')[0])\n",
        "      result[pantano]['Diff'].append(str(j).split('>')[10].split('<')[0].split(' ')[-1])\n",
        "      result[pantano]['hm'].append(str(j).split('>')[7].split('<')[0])\n",
        "    elif len(str(j).split('>'))==9:\n",
        "      result[pantano]['Fecha'].append(str(j).split('>')[2].split('<')[0])\n",
        "      result[pantano]['Diff'].append(str(j).split('>')[6].split('<')[0].split(' ')[-1])\n",
        "      result[pantano]['hm'].append(str(j).split('>')[4].split('<')[0])\n",
        "      "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA1LT4s08FZX"
      },
      "source": [
        "empty=[]\n",
        "for i in result:\n",
        "  if  result[i]== {'Fecha':[],'hm':[],'Diff':[]}:\n",
        "    empty.append(i)\n",
        "for i in empty:\n",
        "  del result[i]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86-twarOAvq2"
      },
      "source": [
        "import pandas as pd\n",
        "df_cmpl=[]\n",
        "for i in result:\n",
        "  df=pd.DataFrame(result[i])\n",
        "  df['Pantano']=i\n",
        "  df_cmpl.append(df)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYwQ2-ml8a4C"
      },
      "source": [
        "df_embalses=pd.concat(df_cmpl)\n",
        "df_embalses.sort_values('Pantano',inplace=True, ascending=True)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "xi3ZUSHz9BZh",
        "outputId": "176d7c89-cccc-4c8c-8793-2df85ec8b0ad"
      },
      "source": [
        "display(df_embalses)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fecha</th>\n",
              "      <th>hm</th>\n",
              "      <th>Diff</th>\n",
              "      <th>Pantano</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>06-11-2021  12:00</td>\n",
              "      <td>13.71</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07-11-2021  00:00</td>\n",
              "      <td>13.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07-11-2021  06:00</td>\n",
              "      <td>13.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>07-11-2021  19:00</td>\n",
              "      <td>13.73</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07-11-2021  18:00</td>\n",
              "      <td>13.73</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07-11-2021  17:00</td>\n",
              "      <td>72.91</td>\n",
              "      <td>0.00</td>\n",
              "      <td>yesa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>07-11-2021  17:50</td>\n",
              "      <td>163.78</td>\n",
              "      <td>0.00</td>\n",
              "      <td>zujar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07-11-2021  10:50</td>\n",
              "      <td>163.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>zujar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07-11-2021  04:50</td>\n",
              "      <td>163.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>zujar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>06-11-2021  10:50</td>\n",
              "      <td>164.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>zujar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>767 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Fecha      hm  Diff  Pantano\n",
              "4   06-11-2021  12:00   13.71  0.00  abellan\n",
              "3   07-11-2021  00:00   13.72  0.00  abellan\n",
              "2   07-11-2021  06:00   13.72  0.00  abellan\n",
              "0   07-11-2021  19:00   13.73  0.00  abellan\n",
              "1   07-11-2021  18:00   13.73  0.00  abellan\n",
              "..                ...     ...   ...      ...\n",
              "1   07-11-2021  17:00   72.91  0.00     yesa\n",
              "0   07-11-2021  17:50  163.78  0.00    zujar\n",
              "1   07-11-2021  10:50  163.89  0.00    zujar\n",
              "2   07-11-2021  04:50  163.89  0.00    zujar\n",
              "3   06-11-2021  10:50  164.11  0.00    zujar\n",
              "\n",
              "[767 rows x 4 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRg3dssTXlj1"
      },
      "source": [
        "### Obtención de las coordenadas de los pantanos wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35_J0cMKNqvg"
      },
      "source": [
        "result_coords={}\n",
        "for i in df_embalses['Pantano'].unique():\n",
        "  page = requests.get('https://es.wikipedia.org/w/index.php?search=embalse+{}&title=Especial:Buscar&profile=advanced&fulltext=1&ns0=1&ns100=1&ns104=1'.format(i))\n",
        "  soup = BeautifulSoup(page.content)\n",
        "  \n",
        "  for j in soup.find_all('a'):\n",
        "    if str(j).split(' ')[1]=='data-serp-pos=\"0\"':\n",
        "      url=\"https://es.wikipedia.org\"+str(str(j).split('href=')[1].split(' ')[0][1:-1])\n",
        "      sub_page=requests.get(url)\n",
        "      sub_soup = BeautifulSoup(sub_page.content)\n",
        "      for z in sub_soup.find_all('a'):\n",
        "        \n",
        "        if str(z).split(' ')[1]=='class=\"external':\n",
        "          if str(z).split('href=')[1].split('\"')[1].startswith('http://tools.wmflabs.org/geohack/geohack.php?language=es&amp;pagename='):\n",
        "            sub_url=str(z).split('href=')[1].split('\"')[1]\n",
        "            sub_sub_page=requests.get(sub_url)\n",
        "            sub_sub_soup = BeautifulSoup(sub_page.content)\n",
        "            for k in sub_sub_soup.find_all('span'):\n",
        "              if str(k).split(' ')[1]=='class=\"geo-dec\"':\n",
        "                result_coords[i]=(str(k).split('<span class=\"latitude\">')[1].split(',')[0],str(k).split('<span class=\"longitude\">')[1].split('<')[0])\n",
        "                break"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqTew3PZP-tq"
      },
      "source": [
        "df_coords=[]\n",
        "for i in result_coords:\n",
        "  df=pd.DataFrame({'Latidud':[result_coords[i][0]],'Longuitud':[result_coords[i][1]]})\n",
        "  df['Pantano']=i\n",
        "  df_coords.append(df)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEJaAuWkXI4T"
      },
      "source": [
        "df_coords=pd.concat(df_coords)\n",
        "df_coords.sort_values('Pantano',inplace=True, ascending=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "BQXe7JdHZcRh",
        "outputId": "9eed71f8-6000-4ead-da40-47e8e60bc3f7"
      },
      "source": [
        "display(df_coords)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Latidud</th>\n",
              "      <th>Longuitud</th>\n",
              "      <th>Pantano</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37.31</td>\n",
              "      <td>-3.27</td>\n",
              "      <td>abellan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39.36840556</td>\n",
              "      <td>-4.253425</td>\n",
              "      <td>abraham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.618672222222</td>\n",
              "      <td>-4.2211527777778</td>\n",
              "      <td>acena</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41.97666667</td>\n",
              "      <td>-6.14472222</td>\n",
              "      <td>agavanzal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37.469722222222</td>\n",
              "      <td>-6.21</td>\n",
              "      <td>agrio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.89305556</td>\n",
              "      <td>-5.49333333</td>\n",
              "      <td>villagonzalo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36.870833</td>\n",
              "      <td>-4.166667</td>\n",
              "      <td>vinuela</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38.215</td>\n",
              "      <td>-1.6001416666667</td>\n",
              "      <td>xiii</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42.615305555556</td>\n",
              "      <td>-1.1713611111111</td>\n",
              "      <td>yesa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38.929827777778</td>\n",
              "      <td>-5.4449277777778</td>\n",
              "      <td>zujar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>196 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Latidud         Longuitud       Pantano\n",
              "0             37.31             -3.27       abellan\n",
              "0       39.36840556         -4.253425       abraham\n",
              "0   40.618672222222  -4.2211527777778         acena\n",
              "0       41.97666667       -6.14472222     agavanzal\n",
              "0   37.469722222222             -6.21         agrio\n",
              "..              ...               ...           ...\n",
              "0       40.89305556       -5.49333333  villagonzalo\n",
              "0         36.870833         -4.166667       vinuela\n",
              "0            38.215  -1.6001416666667          xiii\n",
              "0   42.615305555556  -1.1713611111111          yesa\n",
              "0   38.929827777778  -5.4449277777778         zujar\n",
              "\n",
              "[196 rows x 3 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRZ35Ztja2b2"
      },
      "source": [
        "### JUNTAR LAS TRES FUENES API DE AEMET , EMBALSES.NET Y WIKIPEDIA en un único dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "XkRuhzDFa285",
        "outputId": "a6beb27d-3acf-4a3b-9aac-63bafb37811f"
      },
      "source": [
        "df_embales_coords=pd.merge(df_embalses,df_coords,how='inner',on='Pantano')\n",
        "df_embales_coords"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fecha</th>\n",
              "      <th>hm</th>\n",
              "      <th>Diff</th>\n",
              "      <th>Pantano</th>\n",
              "      <th>Latidud</th>\n",
              "      <th>Longuitud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>06-11-2021  12:00</td>\n",
              "      <td>13.71</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "      <td>37.31</td>\n",
              "      <td>-3.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07-11-2021  00:00</td>\n",
              "      <td>13.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "      <td>37.31</td>\n",
              "      <td>-3.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07-11-2021  06:00</td>\n",
              "      <td>13.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "      <td>37.31</td>\n",
              "      <td>-3.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07-11-2021  19:00</td>\n",
              "      <td>13.73</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "      <td>37.31</td>\n",
              "      <td>-3.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07-11-2021  18:00</td>\n",
              "      <td>13.73</td>\n",
              "      <td>0.00</td>\n",
              "      <td>abellan</td>\n",
              "      <td>37.31</td>\n",
              "      <td>-3.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671</th>\n",
              "      <td>07-11-2021  17:00</td>\n",
              "      <td>72.91</td>\n",
              "      <td>0.00</td>\n",
              "      <td>yesa</td>\n",
              "      <td>42.615305555556</td>\n",
              "      <td>-1.1713611111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>672</th>\n",
              "      <td>07-11-2021  17:50</td>\n",
              "      <td>163.78</td>\n",
              "      <td>0.00</td>\n",
              "      <td>zujar</td>\n",
              "      <td>38.929827777778</td>\n",
              "      <td>-5.4449277777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673</th>\n",
              "      <td>07-11-2021  10:50</td>\n",
              "      <td>163.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>zujar</td>\n",
              "      <td>38.929827777778</td>\n",
              "      <td>-5.4449277777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674</th>\n",
              "      <td>07-11-2021  04:50</td>\n",
              "      <td>163.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>zujar</td>\n",
              "      <td>38.929827777778</td>\n",
              "      <td>-5.4449277777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>675</th>\n",
              "      <td>06-11-2021  10:50</td>\n",
              "      <td>164.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>zujar</td>\n",
              "      <td>38.929827777778</td>\n",
              "      <td>-5.4449277777778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>676 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Fecha      hm  ...          Latidud         Longuitud\n",
              "0    06-11-2021  12:00   13.71  ...            37.31             -3.27\n",
              "1    07-11-2021  00:00   13.72  ...            37.31             -3.27\n",
              "2    07-11-2021  06:00   13.72  ...            37.31             -3.27\n",
              "3    07-11-2021  19:00   13.73  ...            37.31             -3.27\n",
              "4    07-11-2021  18:00   13.73  ...            37.31             -3.27\n",
              "..                 ...     ...  ...              ...               ...\n",
              "671  07-11-2021  17:00   72.91  ...  42.615305555556  -1.1713611111111\n",
              "672  07-11-2021  17:50  163.78  ...  38.929827777778  -5.4449277777778\n",
              "673  07-11-2021  10:50  163.89  ...  38.929827777778  -5.4449277777778\n",
              "674  07-11-2021  04:50  163.89  ...  38.929827777778  -5.4449277777778\n",
              "675  06-11-2021  10:50  164.11  ...  38.929827777778  -5.4449277777778\n",
              "\n",
              "[676 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgniOPNWc0Hq"
      },
      "source": [
        "from math import cos, asin, sqrt\n",
        "\n",
        "def distance(lat1, lon1, lat2, lon2):\n",
        "    #print(lat1, lon1, lat2, lon2)\n",
        "    p = 0.017453292519943295\n",
        "    hav = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n",
        "    return 12742 * asin(sqrt(hav))\n",
        "\n",
        "def closest(data, v):\n",
        "    return min(data, key=lambda p: distance(float(v[0]),float(v[1]),float(p[0]),float(p[1])))\n",
        "    \n",
        "tempDataList=list(zip(df_aemet.iloc[:,2].tolist() ,df_aemet.iloc[:,1].tolist()))\n",
        "\n",
        "nearest_station_lon,nearest_station_lat=[],[]\n",
        "for v in list(zip(df_embales_coords.iloc[:,-2].tolist() ,df_embales_coords.iloc[:,-1].tolist())):\n",
        "  tmp=closest(tempDataList, v)\n",
        "  nearest_station_lat.append(tmp[0])\n",
        "  nearest_station_lon.append(tmp[1])\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoZk1D8GedsV"
      },
      "source": [
        "df_embales_coords['lat']=nearest_station_lat\n",
        "df_embales_coords['lon']=nearest_station_lon"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUOwGvo31kOM"
      },
      "source": [
        "dataset=pd.merge(df_embales_coords,df_aemet,how='inner', on='lat')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtblJebu3AUU"
      },
      "source": [
        "dataset.to_csv('Water-Estimation-Dataset.csv')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P1Xly246l8c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}